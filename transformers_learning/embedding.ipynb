{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding 构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0203, 0.2529],\n",
       "        [0.8478, 0.4440],\n",
       "        [0.6016, 0.4999]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_torch_test = torch.rand(3, 2)\n",
    "random_torch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "# 将输入的词汇表索引转换为指定维度的embedding形式\n",
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        \"\"\"\n",
    "        初始化 TokenEmbedding 类的实例。\n",
    "\n",
    "        参数:\n",
    "        vocab_size (int): 词汇表的大小，即词汇表中唯一词元的数量。\n",
    "        embedding_dim (int): 每个词元对应的嵌入向量的维度。\n",
    "        \"\"\"\n",
    "        # 调用父类 nn.Embedding 的构造函数，初始化词嵌入层\n",
    "        # vocab_size: 词汇表的大小，确定嵌入矩阵的行数\n",
    "        # embedding_dim: 嵌入向量的维度，确定嵌入矩阵的列数\n",
    "        # padding_idx=1: 指定填充词元的索引为 1，该索引对应的嵌入向量将被初始化为全零且不会被训练更新\n",
    "        super(TokenEmbedding, self).__init__(vocab_size, embedding_dim, padding_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建位置编码embedding\n",
    "class PositionEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    位置编码模块，用于为输入序列添加位置信息。\n",
    "    在Transformer架构中，由于模型本身不具备捕捉序列顺序的能力，\n",
    "    因此需要通过位置编码来引入序列中元素的位置信息。\n",
    "\n",
    "    Attributes:\n",
    "        device (torch.device): 计算设备，如 'cpu' 或 'cuda'。\n",
    "        encoding (torch.Tensor): 位置编码矩阵，形状为 (max_len, embedding_dim)。\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, max_len, device):\n",
    "        \"\"\"\n",
    "        初始化位置编码模块。\n",
    "\n",
    "        Args:\n",
    "            embedding_dim (int): 嵌入维度，即每个位置编码向量的长度。\n",
    "            max_len (int): 最大序列长度，即位置编码矩阵的最大行数。\n",
    "            device (torch.device): 计算设备，如 'cpu' 或 'cuda'。\n",
    "        \"\"\"\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.device = device\n",
    "        # 初始化位置编码矩阵，形状为 (max_len, embedding_dim)，初始值全为0\n",
    "        self.encoding = torch.zeros(max_len, embedding_dim, device = self.device)\n",
    "        # 位置编码不需要计算梯度，因为它是固定的\n",
    "        self.encoding.requires_grad = False\n",
    "        # 生成位置索引，形状为 (max_len, 1), 转换为浮点型， 并扩展为 (max_len, embedding_dim)一个二维张量\n",
    "        pos = torch.arange(0, max_len, device=device).float().unsqueeze(dim = 1)\n",
    "        # 生成偶数索引，用于计算正弦和余弦值，形状为 (embedding_dim // 2,)\n",
    "        _2i = torch.arange(0, embedding_dim, step=2, device=device).float()\n",
    "        # 计算位置编码的偶数维度，使用正弦函数\n",
    "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / embedding_dim)))\n",
    "        # 计算位置编码的奇数维度，使用余弦函数\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / embedding_dim)))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播方法，根据输入序列的长度截取相应的位置编码。\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): 输入序列，形状为 (batch_size, seq_len)。\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 截取后的位置编码，形状为 (seq_len, embedding_dim)。\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.size()\n",
    "        # 根据输入序列的长度截取相应的位置编码\n",
    "        return self.encoding[:seq_len, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, max_len, dropout_prob, device):\n",
    "        super(TransformerEmbedding, self).__init__()    \n",
    "        self.token_embedding = TokenEmbedding(vocab_size, embedding_dim)\n",
    "        self.position_embedding = PositionEmbedding(embedding_dim, max_len, device)\n",
    "        # 防止过拟合\n",
    "        self.drop_out = nn.Dropout(p = dropout_prob) \n",
    "\n",
    "    def forward(self, x):\n",
    "        token_embedding = self.token_embedding(x)\n",
    "        position_embedding = self.position_embedding(x)\n",
    "        return self.drop_out(token_embedding + position_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试输入： tensor([[280, 699, 171,   2, 738, 544, 688, 318, 195, 761,  64, 166, 795, 645,\n",
      "         330, 538, 627, 608, 932, 291, 980, 329, 385, 207, 562, 944, 576, 731,\n",
      "         967, 812, 645, 878, 428,   5, 167, 296, 548, 618, 347, 783, 190, 849,\n",
      "         102,   5, 328, 709, 947, 505, 419, 247, 154, 812, 673, 206, 572, 213,\n",
      "         119, 744, 539, 567, 525, 144, 389, 417, 721, 209, 846, 932, 442, 637,\n",
      "         999, 847,  25, 747, 515, 314, 532, 672, 484, 683, 943, 685, 228,  38,\n",
      "         571,  98, 206, 138, 145, 808, 230, 320, 896, 748, 691, 316, 518, 726,\n",
      "         632, 278, 339, 499, 783, 824, 920,   4, 107, 781, 336,   8, 999, 360,\n",
      "         721, 870, 427, 334, 197, 133, 453, 139, 553, 214, 894, 886, 649, 123,\n",
      "         740, 462]])\n",
      "测试输出： tensor([[[-0.0000,  0.5848, -0.2572,  ...,  0.4867,  2.0487,  0.0000],\n",
      "         [ 0.9114,  0.6461,  0.5768,  ...,  1.2462, -0.5499,  0.0000],\n",
      "         [ 1.1638, -0.5677,  0.7471,  ...,  1.1358,  0.0000,  1.1008],\n",
      "         ...,\n",
      "         [-0.0000,  2.2345,  1.9668,  ...,  0.0000,  0.7088,  2.3629],\n",
      "         [ 2.6080,  1.2954,  1.3050,  ...,  1.5792,  1.5657,  1.1047],\n",
      "         [ 0.0000,  0.3439,  1.0010,  ...,  0.4416,  1.3154,  1.2315]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "测试输出维度： torch.Size([1, 128, 512])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 512\n",
    "max_len = 128\n",
    "dropout_prob = 0.1\n",
    "device = 'cpu'\n",
    "# device = 'cuda'\n",
    "\n",
    "test_embedding = TransformerEmbedding(\n",
    "    vocab_size = vocab_size, \n",
    "    embedding_dim = embedding_dim, \n",
    "    max_len = max_len, \n",
    "    dropout_prob = dropout_prob, \n",
    "    device = device\n",
    ")\n",
    "\n",
    "# 按照序列的规定长度拼接一个张量 进入 embedding模块进行embedding构建\n",
    "test_input = torch.randint(0, 1000, (1, max_len))\n",
    "print(\"测试输入：\", test_input)\n",
    "test_output = test_embedding.forward(test_input)\n",
    "print(\"测试输出：\", test_output)\n",
    "print(\"测试输出维度：\", test_output.shape)\n",
    "# 预期输出形状应为 (1, 128, 512)\n",
    "# 1: batch_size（批次大小）\n",
    "# 128: sequence_length（序列长度）\n",
    "# 512: embedding_dim（嵌入维度）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileId": "b8fd560f-3804-4cfc-84c2-fb9515b8aff9",
  "filePath": "/mnt/bn/brench-volume-lq1/my_exploration/LLM_Zero_Learning/transformers_learning/model.ipynb",
  "kernelspec": {
   "display_name": "exploration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
